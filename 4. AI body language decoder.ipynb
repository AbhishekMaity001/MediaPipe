{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Body Language Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Steps to be followed!**\n",
    "\n",
    "0. Install and import Dependencies\n",
    "1. Make some detections\n",
    "2. Capture Landmarks & export the data to the csv file\n",
    "3. Train Custom Model using scikit learn\n",
    "  - Reading the collected csv data and preprocess it\n",
    "  - Train a ML classification model\n",
    "  - Evaluate & Serialize model\n",
    "4. Make Detections with our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dependencies\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Loading the model from mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils # used for drawing utilities for each landmark\n",
    "mp_holistic = mp.solutions.holistic # grabbing the pose estimation model from MediaPipe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our code detecting or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# initiate the holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic :\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame,1)\n",
    "        \n",
    "        # recolor the feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (700, 500))\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # making the detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks) # pose_landmarks, face_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        new_frame_time = time.time()\n",
    "        fps = 1 / (new_frame_time - prev_frame_time)\n",
    "        prev_frame_time = new_frame_time\n",
    "        fps = int(fps)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        # window 1\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.putText(image, \"FPS : \"+str(fps), (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX,fontScale =0.5, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # window 2\n",
    "        # image2 = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        # cv2.rectangle(image2, (0,0), (700, 500), (0, 0, 0), -1)\n",
    "        \n",
    "        \n",
    "    \n",
    "        cv2.putText(image2, \"FPS : \"+str(fps), (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX,fontScale =0.5, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=2, circle_radius=1)\n",
    "                                 ) # FACE_CONNECTIONS POSE_CONNECTIONS HAND_CONNECTIONS\n",
    "        \n",
    "        # right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # left hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # pose detection\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        \n",
    "#         im_v = cv2.hconcat([image, image2])\n",
    "        cv2.imshow('Webcam feed', image)\n",
    "        # cv2.imshow('magic', image2)\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break \n",
    "\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.face_landmarks.landmark[0].visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(results.face_landmarks.landmark) + len(results.pose_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Landmarks & export the data to the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture landmarks & export csv\n",
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just setting up the initial csv file headers here\n",
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks+=['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "\n",
    "# landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating a new csv file and putting all the values into it\n",
    "\n",
    "with open('coords.csv', mode='w', newline='') as file:\n",
    "    csv_writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'Sad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# initiate the holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic :\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame,1)\n",
    "        \n",
    "        # recolor the feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (700, 500))\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # making the detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks) # pose_landmarks, face_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        new_frame_time = time.time()\n",
    "        fps = 1 / (new_frame_time - prev_frame_time)\n",
    "        prev_frame_time = new_frame_time\n",
    "        fps = int(fps)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        # window 1\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.putText(image, \"FPS : \"+str(fps), (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX,fontScale =0.5, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # window 2\n",
    "        # image2 = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        # cv2.rectangle(image2, (0,0), (700, 500), (0, 0, 0), -1)\n",
    "        \n",
    "        \n",
    "    \n",
    "        cv2.putText(image2, \"FPS : \"+str(fps), (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX,fontScale =0.5, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=2, circle_radius=1)\n",
    "                                 ) # FACE_CONNECTIONS POSE_CONNECTIONS HAND_CONNECTIONS\n",
    "        \n",
    "        # right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # left hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # pose detection\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extracting Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extracting Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            # np.array is removing the key from the face and converting into array and flattening it\n",
    "            \n",
    "            # combined rows\n",
    "            row = pose_row + face_row\n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to csv\n",
    "            with open('coords.csv', mode='a', newline='') as file:\n",
    "                csv_writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "#         im_v = cv2.hconcat([image, image2])\n",
    "        cv2.imshow('Webcam feed', image)\n",
    "        # cv2.imshow('magic', image2)\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break \n",
    "\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.pose_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train custom model using scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.464500</td>\n",
       "      <td>0.502762</td>\n",
       "      <td>-0.998931</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495374</td>\n",
       "      <td>0.439670</td>\n",
       "      <td>-0.949244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535553</td>\n",
       "      <td>0.435791</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541045</td>\n",
       "      <td>0.432881</td>\n",
       "      <td>-0.002573</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.477836</td>\n",
       "      <td>0.501838</td>\n",
       "      <td>-0.972011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.511705</td>\n",
       "      <td>0.434388</td>\n",
       "      <td>-0.924944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544801</td>\n",
       "      <td>0.437308</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550186</td>\n",
       "      <td>0.434743</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.478061</td>\n",
       "      <td>0.510395</td>\n",
       "      <td>-0.916264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510327</td>\n",
       "      <td>0.441827</td>\n",
       "      <td>-0.875528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.531035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546598</td>\n",
       "      <td>0.439306</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.552068</td>\n",
       "      <td>0.436360</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.478776</td>\n",
       "      <td>0.513892</td>\n",
       "      <td>-0.857089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512455</td>\n",
       "      <td>0.445663</td>\n",
       "      <td>-0.816722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549362</td>\n",
       "      <td>0.442893</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.554831</td>\n",
       "      <td>0.439442</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.480657</td>\n",
       "      <td>0.515194</td>\n",
       "      <td>-0.764382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.511983</td>\n",
       "      <td>0.446914</td>\n",
       "      <td>-0.719931</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.532369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549882</td>\n",
       "      <td>0.443710</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555247</td>\n",
       "      <td>0.440787</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        z1   v1        x2        y2        z2  \\\n",
       "0  Happy  0.464500  0.502762 -0.998931  1.0  0.495374  0.439670 -0.949244   \n",
       "1  Happy  0.477836  0.501838 -0.972011  1.0  0.511705  0.434388 -0.924944   \n",
       "2  Happy  0.478061  0.510395 -0.916264  1.0  0.510327  0.441827 -0.875528   \n",
       "3  Happy  0.478776  0.513892 -0.857089  1.0  0.512455  0.445663 -0.816722   \n",
       "4  Happy  0.480657  0.515194 -0.764382  1.0  0.511983  0.446914 -0.719931   \n",
       "\n",
       "    v2        x3  ...      z499  v499      x500      y500      z500  v500  \\\n",
       "0  1.0  0.515251  ... -0.015363   0.0  0.535553  0.435791 -0.002426   0.0   \n",
       "1  1.0  0.533198  ... -0.015334   0.0  0.544801  0.437308  0.000042   0.0   \n",
       "2  1.0  0.531035  ... -0.015341   0.0  0.546598  0.439306 -0.000877   0.0   \n",
       "3  1.0  0.533266  ... -0.015668   0.0  0.549362  0.442893 -0.000416   0.0   \n",
       "4  1.0  0.532369  ... -0.016162   0.0  0.549882  0.443710 -0.001274   0.0   \n",
       "\n",
       "       x501      y501      z501  v501  \n",
       "0  0.541045  0.432881 -0.002573   0.0  \n",
       "1  0.550186  0.434743  0.000067   0.0  \n",
       "2  0.552068  0.436360 -0.000909   0.0  \n",
       "3  0.554831  0.439442 -0.000348   0.0  \n",
       "4  0.555247  0.440787 -0.001304   0.0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('coords.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.512122</td>\n",
       "      <td>0.757887</td>\n",
       "      <td>-1.187364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.543400</td>\n",
       "      <td>0.674037</td>\n",
       "      <td>-1.156154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.564510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589313</td>\n",
       "      <td>0.660077</td>\n",
       "      <td>-0.015726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.593605</td>\n",
       "      <td>0.655452</td>\n",
       "      <td>-0.016444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.511149</td>\n",
       "      <td>0.756942</td>\n",
       "      <td>-1.321831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.541856</td>\n",
       "      <td>0.673472</td>\n",
       "      <td>-1.287983</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585215</td>\n",
       "      <td>0.659318</td>\n",
       "      <td>-0.016177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589574</td>\n",
       "      <td>0.654505</td>\n",
       "      <td>-0.016949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.511172</td>\n",
       "      <td>0.760749</td>\n",
       "      <td>-1.167425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.541198</td>\n",
       "      <td>0.676570</td>\n",
       "      <td>-1.132153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585387</td>\n",
       "      <td>0.658131</td>\n",
       "      <td>-0.017344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589706</td>\n",
       "      <td>0.653598</td>\n",
       "      <td>-0.018178</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.507611</td>\n",
       "      <td>0.756229</td>\n",
       "      <td>-1.305783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.537963</td>\n",
       "      <td>0.673067</td>\n",
       "      <td>-1.273794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.558956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582193</td>\n",
       "      <td>0.656244</td>\n",
       "      <td>-0.015110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586424</td>\n",
       "      <td>0.651833</td>\n",
       "      <td>-0.015884</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.505599</td>\n",
       "      <td>0.749847</td>\n",
       "      <td>-1.285813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.535971</td>\n",
       "      <td>0.667493</td>\n",
       "      <td>-1.255865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.556912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583438</td>\n",
       "      <td>0.655235</td>\n",
       "      <td>-0.017259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587818</td>\n",
       "      <td>0.650775</td>\n",
       "      <td>-0.018141</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    class        x1        y1        z1   v1        x2        y2        z2  \\\n",
       "763   Sad  0.512122  0.757887 -1.187364  1.0  0.543400  0.674037 -1.156154   \n",
       "764   Sad  0.511149  0.756942 -1.321831  1.0  0.541856  0.673472 -1.287983   \n",
       "765   Sad  0.511172  0.760749 -1.167425  1.0  0.541198  0.676570 -1.132153   \n",
       "766   Sad  0.507611  0.756229 -1.305783  1.0  0.537963  0.673067 -1.273794   \n",
       "767   Sad  0.505599  0.749847 -1.285813  1.0  0.535971  0.667493 -1.255865   \n",
       "\n",
       "      v2        x3  ...      z499  v499      x500      y500      z500  v500  \\\n",
       "763  1.0  0.564510  ... -0.029626   0.0  0.589313  0.660077 -0.015726   0.0   \n",
       "764  1.0  0.562987  ... -0.029243   0.0  0.585215  0.659318 -0.016177   0.0   \n",
       "765  1.0  0.562120  ... -0.030259   0.0  0.585387  0.658131 -0.017344   0.0   \n",
       "766  1.0  0.558956  ... -0.028260   0.0  0.582193  0.656244 -0.015110   0.0   \n",
       "767  1.0  0.556912  ... -0.029957   0.0  0.583438  0.655235 -0.017259   0.0   \n",
       "\n",
       "         x501      y501      z501  v501  \n",
       "763  0.593605  0.655452 -0.016444   0.0  \n",
       "764  0.589574  0.654505 -0.016949   0.0  \n",
       "765  0.589706  0.653598 -0.018178   0.0  \n",
       "766  0.586424  0.651833 -0.015884   0.0  \n",
       "767  0.587818  0.650775 -0.018141   0.0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Victorious    209\n",
       "Sad           206\n",
       "Happy         202\n",
       "Surprise      151\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 231)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test) # checking the len of train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline # used to make a pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr' : make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc' : make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf' : make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb' : make_pipeline(StandardScaler(), GradientBoostingClassifier())\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('ridgeclassifier', RidgeClassifier())]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('gradientboostingclassifier', GradientBoostingClassifier())])])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipelines.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anacondafiles\\envs\\deeplearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Now training the models\n",
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Sad', 'Happy', 'Victorious', 'Victorious', 'Victorious',\n",
       "       'Victorious', 'Victorious', 'Victorious', 'Happy', 'Victorious',\n",
       "       'Surprise', 'Surprise', 'Happy', 'Happy', 'Sad', 'Happy', 'Happy',\n",
       "       'Happy', 'Sad', 'Surprise', 'Happy', 'Victorious', 'Happy',\n",
       "       'Victorious', 'Sad', 'Victorious', 'Surprise', 'Happy', 'Sad',\n",
       "       'Sad', 'Victorious', 'Victorious', 'Surprise', 'Victorious', 'Sad',\n",
       "       'Sad', 'Happy', 'Happy', 'Sad', 'Sad', 'Sad', 'Surprise', 'Happy',\n",
       "       'Victorious', 'Happy', 'Victorious', 'Victorious', 'Sad', 'Happy',\n",
       "       'Surprise', 'Happy', 'Victorious', 'Sad', 'Surprise', 'Victorious',\n",
       "       'Victorious', 'Sad', 'Sad', 'Victorious', 'Sad', 'Surprise',\n",
       "       'Victorious', 'Sad', 'Surprise', 'Victorious', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Sad', 'Happy', 'Sad', 'Sad',\n",
       "       'Victorious', 'Victorious', 'Happy', 'Sad', 'Surprise', 'Happy',\n",
       "       'Sad', 'Surprise', 'Happy', 'Victorious', 'Victorious', 'Happy',\n",
       "       'Happy', 'Sad', 'Sad', 'Happy', 'Surprise', 'Happy', 'Sad',\n",
       "       'Victorious', 'Sad', 'Victorious', 'Surprise', 'Victorious', 'Sad',\n",
       "       'Sad', 'Happy', 'Sad', 'Happy', 'Happy', 'Victorious',\n",
       "       'Victorious', 'Sad', 'Happy', 'Surprise', 'Happy', 'Sad',\n",
       "       'Surprise', 'Happy', 'Happy', 'Sad', 'Sad', 'Happy', 'Sad', 'Sad',\n",
       "       'Victorious', 'Happy', 'Sad', 'Surprise', 'Surprise', 'Happy',\n",
       "       'Happy', 'Sad', 'Victorious', 'Victorious', 'Victorious', 'Happy',\n",
       "       'Happy', 'Surprise', 'Happy', 'Surprise', 'Victorious',\n",
       "       'Victorious', 'Victorious', 'Happy', 'Surprise', 'Victorious',\n",
       "       'Happy', 'Surprise', 'Happy', 'Surprise', 'Sad', 'Surprise',\n",
       "       'Happy', 'Victorious', 'Sad', 'Surprise', 'Victorious', 'Sad',\n",
       "       'Happy', 'Surprise', 'Sad', 'Victorious', 'Sad', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Happy', 'Sad', 'Surprise', 'Surprise',\n",
       "       'Sad', 'Happy', 'Happy', 'Sad', 'Victorious', 'Surprise', 'Happy',\n",
       "       'Sad', 'Happy', 'Surprise', 'Happy', 'Happy', 'Sad', 'Happy',\n",
       "       'Sad', 'Sad', 'Happy', 'Sad', 'Happy', 'Victorious', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Surprise', 'Surprise', 'Victorious',\n",
       "       'Sad', 'Happy', 'Victorious', 'Sad', 'Victorious', 'Sad',\n",
       "       'Victorious', 'Sad', 'Victorious', 'Surprise', 'Victorious',\n",
       "       'Victorious', 'Sad', 'Happy', 'Victorious', 'Happy', 'Surprise',\n",
       "       'Victorious', 'Surprise', 'Victorious', 'Victorious', 'Happy',\n",
       "       'Surprise', 'Happy', 'Happy', 'Sad', 'Sad', 'Surprise', 'Sad',\n",
       "       'Happy', 'Sad', 'Sad', 'Happy', 'Victorious', 'Surprise', 'Sad',\n",
       "       'Sad', 'Happy', 'Happy', 'Victorious', 'Surprise'], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['gb'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9913419913419913\n",
      "rc 0.9956709956709957\n",
      "rf 0.987012987012987\n",
      "gb 0.987012987012987\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "for algo, model in fit_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Sad', 'Happy', 'Victorious', 'Victorious', 'Victorious',\n",
       "       'Victorious', 'Victorious', 'Victorious', 'Happy', 'Victorious',\n",
       "       'Surprise', 'Surprise', 'Happy', 'Happy', 'Sad', 'Happy', 'Happy',\n",
       "       'Happy', 'Sad', 'Surprise', 'Happy', 'Happy', 'Happy',\n",
       "       'Victorious', 'Sad', 'Victorious', 'Surprise', 'Happy', 'Sad',\n",
       "       'Sad', 'Victorious', 'Victorious', 'Surprise', 'Victorious', 'Sad',\n",
       "       'Sad', 'Happy', 'Happy', 'Sad', 'Sad', 'Sad', 'Surprise', 'Happy',\n",
       "       'Victorious', 'Happy', 'Victorious', 'Victorious', 'Sad', 'Happy',\n",
       "       'Surprise', 'Happy', 'Victorious', 'Sad', 'Surprise', 'Victorious',\n",
       "       'Victorious', 'Sad', 'Sad', 'Victorious', 'Sad', 'Surprise',\n",
       "       'Victorious', 'Sad', 'Surprise', 'Victorious', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Sad', 'Happy', 'Sad', 'Sad',\n",
       "       'Victorious', 'Victorious', 'Happy', 'Sad', 'Surprise', 'Happy',\n",
       "       'Sad', 'Surprise', 'Happy', 'Victorious', 'Victorious', 'Happy',\n",
       "       'Happy', 'Sad', 'Happy', 'Happy', 'Surprise', 'Happy', 'Sad',\n",
       "       'Victorious', 'Sad', 'Victorious', 'Surprise', 'Victorious', 'Sad',\n",
       "       'Sad', 'Happy', 'Sad', 'Happy', 'Happy', 'Victorious',\n",
       "       'Victorious', 'Sad', 'Happy', 'Surprise', 'Happy', 'Sad',\n",
       "       'Surprise', 'Happy', 'Happy', 'Surprise', 'Sad', 'Happy', 'Sad',\n",
       "       'Sad', 'Victorious', 'Happy', 'Sad', 'Surprise', 'Surprise',\n",
       "       'Happy', 'Happy', 'Sad', 'Victorious', 'Victorious', 'Victorious',\n",
       "       'Happy', 'Happy', 'Surprise', 'Happy', 'Surprise', 'Victorious',\n",
       "       'Victorious', 'Victorious', 'Happy', 'Surprise', 'Victorious',\n",
       "       'Happy', 'Surprise', 'Happy', 'Surprise', 'Sad', 'Surprise',\n",
       "       'Happy', 'Victorious', 'Sad', 'Surprise', 'Victorious', 'Sad',\n",
       "       'Happy', 'Surprise', 'Sad', 'Victorious', 'Sad', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Happy', 'Sad', 'Surprise', 'Surprise',\n",
       "       'Sad', 'Happy', 'Happy', 'Sad', 'Victorious', 'Surprise', 'Happy',\n",
       "       'Sad', 'Happy', 'Surprise', 'Happy', 'Sad', 'Sad', 'Happy', 'Sad',\n",
       "       'Sad', 'Happy', 'Sad', 'Happy', 'Victorious', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Surprise', 'Surprise', 'Victorious',\n",
       "       'Sad', 'Happy', 'Victorious', 'Sad', 'Victorious', 'Sad',\n",
       "       'Victorious', 'Sad', 'Victorious', 'Surprise', 'Victorious',\n",
       "       'Victorious', 'Sad', 'Happy', 'Victorious', 'Happy', 'Surprise',\n",
       "       'Victorious', 'Surprise', 'Victorious', 'Victorious', 'Happy',\n",
       "       'Surprise', 'Happy', 'Happy', 'Sad', 'Sad', 'Surprise', 'Sad',\n",
       "       'Happy', 'Sad', 'Sad', 'Happy', 'Victorious', 'Surprise', 'Sad',\n",
       "       'Sad', 'Happy', 'Happy', 'Victorious', 'Surprise'], dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766           Sad\n",
       "748           Sad\n",
       "42          Happy\n",
       "485    Victorious\n",
       "543    Victorious\n",
       "          ...    \n",
       "188           Sad\n",
       "8           Happy\n",
       "645         Happy\n",
       "381    Victorious\n",
       "314      Surprise\n",
       "Name: class, Length: 231, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_lang.pkl', 'wb') as file:\n",
    "    pickle.dump(fit_models['rf'], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Detections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_lang.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the below cell to view the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# initiate the holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic :\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame,1)\n",
    "        \n",
    "        # recolor the feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (700, 500))\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # making the detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks) # pose_landmarks, face_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        new_frame_time = time.time()\n",
    "        fps = 1 / (new_frame_time - prev_frame_time)\n",
    "        prev_frame_time = new_frame_time\n",
    "        fps = int(fps)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        # window 1\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.putText(image, \"FPS : \"+str(fps), (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX,fontScale =0.5, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # window 2\n",
    "        # image2 = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        # cv2.rectangle(image2, (0,0), (700, 500), (0, 0, 0), -1)\n",
    "        \n",
    "        \n",
    "    \n",
    "        # cv2.putText(image2, \"FPS : \"+str(fps), (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX,fontScale =0.5, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # Draw face landmarks\n",
    "#         mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "#                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=1),\n",
    "#                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2, circle_radius=1)\n",
    "#                                  ) # FACE_CONNECTIONS POSE_CONNECTIONS HAND_CONNECTIONS\n",
    "        \n",
    "        # right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # left hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # pose detection\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "#                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "        \n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extracting Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extracting Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            # np.array is removing the key from the face and converting into array and flattening it\n",
    "            \n",
    "            # combined rows\n",
    "            row = pose_row + face_row\n",
    "            # row.insert(0, class_name)\n",
    "            \n",
    "            # Export to csv\n",
    "#             with open('coords.csv', mode='a', newline='') as file:\n",
    "#                 csv_writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row)\n",
    "\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_cls = model.predict(X)[0]\n",
    "            body_language_proba = model.predict_proba(X)[0]\n",
    "            # print(body_language_cls, body_language_proba)\n",
    "            \n",
    "            \n",
    "            # grab the coords of the ear so that it will display the predicted label beside the ear\n",
    "            coords = tuple(np.multiply(np.array((results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)),\n",
    "                                 [700,500]).astype(int))\n",
    "            # print(coords)\n",
    "            \n",
    "            \n",
    "            cv2.rectangle(image,\n",
    "                         (coords[0], coords[1]+5),\n",
    "                         (coords[0]+len(body_language_cls)*20, coords[1]-30),\n",
    "                         (0, 0, 0), -1)\n",
    "            cv2.putText(image, body_language_cls, coords, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "                                        \n",
    "            \n",
    "            # box at top left corner for status\n",
    "            cv2.rectangle(image, (0,0), (350,50), (0, 0, 0), -1)\n",
    "            \n",
    "            # display class in that rectangle\n",
    "            cv2.putText(image, 'STATUS : ', (10,18), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_cls.split(' ')[0], (100,20), cv2.FONT_HERSHEY_COMPLEX, 1, (186, 219, 75), 1, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(image, 'CONF : ', (10,40), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_proba[np.argmax(body_language_proba)],2)), (50, 45), cv2.FONT_HERSHEY_COMPLEX, 1, (186, 219, 75), 1, cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "#         im_v = cv2.hconcat([image, image2])\n",
    "        cv2.imshow('Webcam feed', image)\n",
    "        # cv2.imshow('magic', image2)\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break \n",
    "\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
