{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"utils/mediapipelogo.png\" width=\"700\" height=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **official documentation** : https://google.github.io/mediapipe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe opencv-python # install mediapipe and opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the mediapipe libraries\n",
    "import mediapipe as mp\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many different pre-trained models available in MediaPipe here we will use Holistic model\n",
    "# Loading the Holistic model and drawing_utils to draw the detections\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting raw webcam feed also checking the FPS in Raw Webcam feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "    \n",
    "    # FPS Frame\n",
    "    new_frame_time = time.time()\n",
    "    fps = 1 / (new_frame_time - prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "    fps = int(fps)\n",
    "    \n",
    "    cv2.putText(frame, \"FPS : \"+str(fps), (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX,fontScale =0.5, color=(0, 255, 0), thickness=2)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('Raw Webcam feed', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making detections & Apply Styling from the raw feed\n",
    "\n",
    "1. **Detect Facial Landmarks**\n",
    "2. **Detect Hand Poses**\n",
    "3. **Detect Body Poses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_drawing.DrawingSpec(color=(0, 0, 255),thickness=2,circle_radius=3) # for setting the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing.draw_landmarks?? # Execute this cell to get more info on .draw_landmarks function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the below cell to see the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# initiate the holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic :\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame,1)\n",
    "        \n",
    "        # recoloring the feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (700, 500))\n",
    "        \n",
    "        # making the detections\n",
    "        results = holistic.process(image)\n",
    "#         print(results.face_landmarks) # pose_landmarks, face_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "    \n",
    "        # window 1\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.putText(image, \"FPS : \"+str(fps), (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX,fontScale =0.5, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # window 2\n",
    "        image2 = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.rectangle(image2, (0,0), (700, 500), (0, 0, 0), -1)\n",
    "        \n",
    "        new_frame_time = time.time()\n",
    "        fps = 1 / (new_frame_time - prev_frame_time)\n",
    "        prev_frame_time = new_frame_time\n",
    "        fps = int(fps)\n",
    "    \n",
    "        cv2.putText(image2, \"FPS : \"+str(fps), (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX,fontScale =0.5, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image2, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=2, circle_radius=1)\n",
    "                                 ) # FACE_CONNECTIONS POSE_CONNECTIONS HAND_CONNECTIONS\n",
    "        \n",
    "        # right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # left hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # pose detection\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        \n",
    "#         im_v = cv2.hconcat([image, image2])\n",
    "        cv2.imshow('Webcam feed', image)\n",
    "        cv2.imshow('magic', image2)\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break \n",
    "\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(<HandLandmark.WRIST: 0>, <HandLandmark.THUMB_CMC: 1>),\n",
       "           (<HandLandmark.WRIST: 0>, <HandLandmark.INDEX_FINGER_MCP: 5>),\n",
       "           (<HandLandmark.WRIST: 0>, <HandLandmark.PINKY_MCP: 17>),\n",
       "           (<HandLandmark.THUMB_CMC: 1>, <HandLandmark.THUMB_MCP: 2>),\n",
       "           (<HandLandmark.THUMB_MCP: 2>, <HandLandmark.THUMB_IP: 3>),\n",
       "           (<HandLandmark.THUMB_IP: 3>, <HandLandmark.THUMB_TIP: 4>),\n",
       "           (<HandLandmark.INDEX_FINGER_MCP: 5>,\n",
       "            <HandLandmark.INDEX_FINGER_PIP: 6>),\n",
       "           (<HandLandmark.INDEX_FINGER_MCP: 5>,\n",
       "            <HandLandmark.MIDDLE_FINGER_MCP: 9>),\n",
       "           (<HandLandmark.INDEX_FINGER_PIP: 6>,\n",
       "            <HandLandmark.INDEX_FINGER_DIP: 7>),\n",
       "           (<HandLandmark.INDEX_FINGER_DIP: 7>,\n",
       "            <HandLandmark.INDEX_FINGER_TIP: 8>),\n",
       "           (<HandLandmark.MIDDLE_FINGER_MCP: 9>,\n",
       "            <HandLandmark.MIDDLE_FINGER_PIP: 10>),\n",
       "           (<HandLandmark.MIDDLE_FINGER_MCP: 9>,\n",
       "            <HandLandmark.RING_FINGER_MCP: 13>),\n",
       "           (<HandLandmark.MIDDLE_FINGER_PIP: 10>,\n",
       "            <HandLandmark.MIDDLE_FINGER_DIP: 11>),\n",
       "           (<HandLandmark.MIDDLE_FINGER_DIP: 11>,\n",
       "            <HandLandmark.MIDDLE_FINGER_TIP: 12>),\n",
       "           (<HandLandmark.RING_FINGER_MCP: 13>,\n",
       "            <HandLandmark.RING_FINGER_PIP: 14>),\n",
       "           (<HandLandmark.RING_FINGER_MCP: 13>, <HandLandmark.PINKY_MCP: 17>),\n",
       "           (<HandLandmark.RING_FINGER_PIP: 14>,\n",
       "            <HandLandmark.RING_FINGER_DIP: 15>),\n",
       "           (<HandLandmark.RING_FINGER_DIP: 15>,\n",
       "            <HandLandmark.RING_FINGER_TIP: 16>),\n",
       "           (<HandLandmark.PINKY_MCP: 17>, <HandLandmark.PINKY_PIP: 18>),\n",
       "           (<HandLandmark.PINKY_PIP: 18>, <HandLandmark.PINKY_DIP: 19>),\n",
       "           (<HandLandmark.PINKY_DIP: 19>, <HandLandmark.PINKY_TIP: 20>)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_holistic.HAND_CONNECTIONS # We can see there are different landmarks (indexes) detected by the mediapipe Holistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
